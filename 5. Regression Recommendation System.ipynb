{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77f976a",
   "metadata": {},
   "source": [
    "# The Regression Recommendation System "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344c3f3",
   "metadata": {},
   "source": [
    "### Setting up enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2e5d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1658.3 KiB\n"
     ]
    }
   ],
   "source": [
    "# Python stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PySpark stuff\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType, BooleanType, DateType, FloatType\n",
    "from pyspark.sql.functions import isnan, when, count, col, avg, mean, sqrt, desc\n",
    "\n",
    "\n",
    "# ML stuff\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "383f5d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession    \\\n",
    "  .builder              \\\n",
    "  .master('yarn')       \\\n",
    "  .appName('spark')     \\\n",
    "  .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31811567",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"big-data-yelp\"\n",
    "spark.conf.set('temporaryGcsBucket', bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1d89409",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e05302",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39acd6c",
   "metadata": {},
   "source": [
    "### Import Business Basic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71f2ebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1518.4 KiB\n",
      "22/03/16 02:30:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1289.6 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------------+----------------+---------+-----+-----------+-------------+---------------+-----+------------+-------+--------------------+\n",
      "|int64_field_0|         business_id|            name|         address|     city|state|postal_code|     latitude|      longitude|stars|review_count|is_open|          categories|\n",
      "+-------------+--------------------+----------------+----------------+---------+-----+-----------+-------------+---------------+-----+------------+-------+--------------------+\n",
      "|        10020|2tgAgCI8EJUA16EN4...|     Shaw Direct|W Georgia Street|Vancouver|   BC|       null|    49.285726|   -123.1231553|  2.0|           5|      1|Home Services, Pr...|\n",
      "|        32306|wzwGYL2M4SvoLgTok...|Austin Tree Pros|            null|   Austin|   TX|       null|    30.267153|    -97.7430608|  2.0|           5|      1|Tree Services, La...|\n",
      "|        37509|Tsk7LgyqWSwQSumLj...|   Pacific Grill|            null|Vancouver|   BC|       null|49.1981952989|-123.1751060486|  2.0|           7|      1|Restaurants, Cana...|\n",
      "+-------------+--------------------+----------------+----------------+---------+-----+-----------+-------------+---------------+-----+------------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = 'red-formula-339716:gfds.yelp_business_basicdata'\n",
    "df_b = spark.read.format('bigquery').option('table', table).load()\n",
    "df_b.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57fe03e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:32 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1043.6 KiB\n"
     ]
    }
   ],
   "source": [
    "# Filtering to only restuarants in Ohio.\n",
    "df_b = df_b.filter(df_b.state.like(\"OH\")).filter(df_b.categories.like(\"%Restaurants%\")).drop('int64_field_0', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7511446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-----+------------+-------+--------------------+\n",
      "|         business_id|           name|stars|review_count|is_open|          categories|\n",
      "+--------------------+---------------+-----+------------+-------+--------------------+\n",
      "|_rpEhHWZmwnUWe96e...|      Bob Evans|  2.0|          38|      1|Salad, Hotels & T...|\n",
      "|2R_hRr--5V1krRMfm...|En Super Buffet|  2.0|           5|      0|Chinese, Restaurants|\n",
      "|H82T5LaYRnL9BispF...| Domino's Pizza|  2.0|          12|      1|Restaurants, Pizz...|\n",
      "+--------------------+---------------+-----+------------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_b.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2785b",
   "metadata": {},
   "source": [
    "### Get Most Commenting Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d782f",
   "metadata": {},
   "source": [
    "Finding the most commenting users in OH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47a5b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|y-vHCBFQCDMwzsMwJ...|   0|2015-01-06 20:45:46|    0|BB499lAH9E4kZHRRN...|  5.0|I love this place...|     2|6iyM-H6_bI13gl4Zn...|\n",
      "|P0Ltl7wZFDlHofnPq...|   0|2008-06-25 00:36:30|    1|oCFAPXs9lKU2vmugZ...|  4.0|This is a really ...|     1|FVk12H4Cz4DkRzl8N...|\n",
      "|Sx0IM4UyHbrRrA6Qe...|   0|2017-07-02 19:55:08|    2|35sl486eWMuDrMbrH...|  1.0|It's odd to see a...|     1|9Mhv0W8S61JbIE8ZY...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = 'red-formula-339716:gfds.yelp_review'\n",
    "df_r = spark.read.format('bigquery').option('table', table).load()\n",
    "df_r.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9b858e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join to get only Ohio restaurants.\n",
    "df_rb = df_r.join(df_b.drop('stars'), on = 'business_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47c5ef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|user_id               |count|\n",
      "+----------------------+-----+\n",
      "|C1kTSvNdJH_S2bBhitr6ZA|917  |\n",
      "|R1FVpAyl_BtxHBWdau2VLg|890  |\n",
      "|JzP5uJjhZb0Vj8J_bn3mOg|748  |\n",
      "|tgeFUChlh7v8bZFVl2-hjQ|625  |\n",
      "|wZ0KFPTp1263hDl2M0gXGg|463  |\n",
      "+----------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the most active users\n",
    "df_rb.groupBy('user_id').count().orderBy('count', ascending = False).show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd16327",
   "metadata": {},
   "source": [
    "C1kTSvNdJH_S2bBhitr6ZA, R1FVpAyl_BtxHBWdau2VLg, JzP5uJjhZb0Vj8J_bn3mOg, tgeFUChlh7v8bZFVl2-hjQ   \n",
    "are the most active users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e6b88",
   "metadata": {},
   "source": [
    "### Get Top Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21dbda0",
   "metadata": {},
   "source": [
    "Getting to top categories in OH restuarants to serve as inputs to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32beb6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1113.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+\n",
      "|categories               |count|\n",
      "+-------------------------+-----+\n",
      "|Restaurants              |4377 |\n",
      "|Food                     |1276 |\n",
      "|Nightlife                |809  |\n",
      "|Bars                     |784  |\n",
      "|Fast Food                |776  |\n",
      "|American (Traditional)   |771  |\n",
      "|Sandwiches               |719  |\n",
      "|Pizza                    |679  |\n",
      "|American (New)           |515  |\n",
      "|Burgers                  |507  |\n",
      "|Breakfast & Brunch       |488  |\n",
      "|Mexican                  |389  |\n",
      "|Salad                    |353  |\n",
      "|Coffee & Tea             |320  |\n",
      "|Chinese                  |304  |\n",
      "|Italian                  |295  |\n",
      "|Chicken Wings            |269  |\n",
      "|Event Planning & Services|244  |\n",
      "|Sports Bars              |199  |\n",
      "|Delis                    |178  |\n",
      "+-------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the PySpark explode function to get top categories.\n",
    "from pyspark.sql.functions import explode, split, col\n",
    "df_b_explode = df_b.withColumn('categories',(explode(split(col(\"categories\"), \", \"))))\n",
    "df_b_explode.groupby('categories').count().orderBy('count', ascending= 0).show(20, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25a997fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top categories!\n",
    "interested_list = ['Nightlife', 'Bars', 'Fast Food', 'American (Traditional)', 'Sandwiches', 'Pizza', 'American (New)', 'Burgers', 'Breakfast & Brunch', 'Mexican', 'Salad', 'Coffee & Tea', 'Chinese', 'Italian', 'Chicken Wings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72ff02e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-----+------------+-------+---------+----+---------+----------------------+----------+-----+--------------+-------+------------------+-------+-----+------------+-------+-------+-------------+\n",
      "|         business_id|           name|stars|review_count|is_open|Nightlife|Bars|Fast Food|American (Traditional)|Sandwiches|Pizza|American (New)|Burgers|Breakfast & Brunch|Mexican|Salad|Coffee & Tea|Chinese|Italian|Chicken Wings|\n",
      "+--------------------+---------------+-----+------------+-------+---------+----+---------+----------------------+----------+-----+--------------+-------+------------------+-------+-----+------------+-------+-------+-------------+\n",
      "|_rpEhHWZmwnUWe96e...|      Bob Evans|  2.0|          38|      1|        0|   0|        0|                     1|         0|    0|             0|      0|                 1|      0|    1|           0|      0|      0|            0|\n",
      "|2R_hRr--5V1krRMfm...|En Super Buffet|  2.0|           5|      0|        0|   0|        0|                     0|         0|    0|             0|      0|                 0|      0|    0|           0|      1|      0|            0|\n",
      "|H82T5LaYRnL9BispF...| Domino's Pizza|  2.0|          12|      1|        0|   0|        0|                     0|         1|    1|             0|      0|                 0|      0|    0|           0|      0|      0|            1|\n",
      "+--------------------+---------------+-----+------------+-------+---------+----+---------+----------------------+----------+-----+--------------+-------+------------------+-------+-----+------------+-------+-------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in interested_list:\n",
    "    df_b = df_b.withColumn(c, F.array_contains(split(col(\"categories\"), ', '), c).cast(\"int\"))\n",
    "df_b = df_b.drop(\"categories\")\n",
    "df_b.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae9332f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename spaces, special punctuation marks, and special character.\n",
    "df_b = df_b.withColumnRenamed(\"American (Traditional)\",\"American_Traditional\")  \\\n",
    "           .withColumnRenamed(\"American (New)\",\"American_New\")                  \\\n",
    "           .withColumnRenamed(\"Breakfast & Brunch\",\"Breakfast_Brunch\")          \\\n",
    "           .withColumnRenamed(\"Coffee & Tea\",\"Coffee_Tea\")                      \\\n",
    "           .withColumnRenamed(\"Chicken Wings\",\"Chicken_Wings\")                  \\\n",
    "           .withColumnRenamed(\"Fast Food\",\"Fast_Food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec1496",
   "metadata": {},
   "source": [
    "### Add Parking Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e83f9ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+------+-----+---------+\n",
      "|         business_id|garage|  lot|street|valet|validated|\n",
      "+--------------------+------+-----+------+-----+---------+\n",
      "|tCbdrRPZA0oiIYSmH...|  true|false| false|false|    false|\n",
      "|hcRxdDg7DYryCxCoI...|  true|false| false|false|    false|\n",
      "|jGennaZUr2MsJyRhi...|  true|false| false|false|    false|\n",
      "+--------------------+------+-----+------+-----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = 'red-formula-339716:gfds.yelp_business_businessparking'\n",
    "df_park = spark.read.format('bigquery').option('table', table).load()\n",
    "df_park.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd53c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---+------+-----+---------+\n",
      "|         business_id|garage|lot|street|valet|validated|\n",
      "+--------------------+------+---+------+-----+---------+\n",
      "|tCbdrRPZA0oiIYSmH...|     1|  0|     0|    0|        0|\n",
      "|hcRxdDg7DYryCxCoI...|     1|  0|     0|    0|        0|\n",
      "|jGennaZUr2MsJyRhi...|     1|  0|     0|    0|        0|\n",
      "+--------------------+------+---+------+-----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cast to 1 and 0\n",
    "cols = ['garage', 'lot', 'street', 'valet', 'validated']\n",
    "df_park = reduce(lambda df_park, c: df_park.withColumn(c, F.when(df_park[c] == 'false', 0).otherwise(1)), cols, df_park)\n",
    "df_park.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9114466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to the business table\n",
    "df_b = df_b.join(df_park, on = 'business_id', how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6860dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1113.5 KiB\n",
      "22/03/16 02:30:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1284.9 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-----+------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+\n",
      "|         business_id|           name|stars|review_count|is_open|Nightlife|Bars|Fast_Food|American_Traditional|Sandwiches|Pizza|American_New|Burgers|Breakfast_Brunch|Mexican|Salad|Coffee_Tea|Chinese|Italian|Chicken_Wings|garage|lot|street|valet|validated|\n",
      "+--------------------+---------------+-----+------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+\n",
      "|_rpEhHWZmwnUWe96e...|      Bob Evans|  2.0|          38|      1|        0|   0|        0|                   1|         0|    0|           0|      0|               1|      0|    1|         0|      0|      0|            0|     0|  1|     0|    0|        0|\n",
      "|2R_hRr--5V1krRMfm...|En Super Buffet|  2.0|           5|      0|        0|   0|        0|                   0|         0|    0|           0|      0|               0|      0|    0|         0|      1|      0|            0|     0|  0|     0|    0|        0|\n",
      "|H82T5LaYRnL9BispF...| Domino's Pizza|  2.0|          12|      1|        0|   0|        0|                   0|         1|    1|           0|      0|               0|      0|    0|         0|      0|      0|            1|     0|  1|     0|    0|        0|\n",
      "+--------------------+---------------+-----+------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_b.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0dbd1",
   "metadata": {},
   "source": [
    "### Add Ambience Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93627ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1441.0 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "|         business_id|casual|classy|divey|hipster|intimate|romantic|touristy|trendy|upscale|\n",
      "+--------------------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "|arEXRZYu8220bFBJ3...| false| false|false|  false|   false|   false|   false|  true|  false|\n",
      "|t2xsi7qIN0iwGiOyC...| false| false| true|  false|   false|   false|   false| false|  false|\n",
      "|N6usNa3_rcYOb8NQ7...| false| false|false|   true|   false|   false|   false| false|  false|\n",
      "+--------------------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1585.4 KiB\n"
     ]
    }
   ],
   "source": [
    "table = 'red-formula-339716:gfds.yelp_business_ambience'\n",
    "df_ambience = spark.read.format('bigquery').option('table', table).load()\n",
    "df_ambience.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e9aa04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "|         business_id|casual|classy|divey|hipster|intimate|romantic|touristy|trendy|upscale|\n",
      "+--------------------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "|arEXRZYu8220bFBJ3...|     0|     0|    0|      0|       0|       0|       0|     1|      0|\n",
      "|t2xsi7qIN0iwGiOyC...|     0|     0|    1|      0|       0|       0|       0|     0|      0|\n",
      "|N6usNa3_rcYOb8NQ7...|     0|     0|    0|      1|       0|       0|       0|     0|      0|\n",
      "+--------------------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1715.5 KiB\n"
     ]
    }
   ],
   "source": [
    "# Cast to 1 and 0\n",
    "cols = ['casual', 'classy', 'divey', 'hipster', 'intimate', 'romantic', 'touristy', 'trendy', 'upscale']\n",
    "df_ambience = reduce(lambda df_ambience, c: df_ambience.withColumn(c, F.when(df_ambience[c] == 'false', 0).otherwise(1)), cols, df_ambience)\n",
    "df_ambience.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0d66720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to the business table\n",
    "df_b = df_b.join(df_ambience, on = 'business_id', how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4928eb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1821.3 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "|         business_id|                name|stars|review_count|is_open|Nightlife|Bars|Fast_Food|American_Traditional|Sandwiches|Pizza|American_New|Burgers|Breakfast_Brunch|Mexican|Salad|Coffee_Tea|Chinese|Italian|Chicken_Wings|garage|lot|street|valet|validated|casual|classy|divey|hipster|intimate|romantic|touristy|trendy|upscale|\n",
      "+--------------------+--------------------+-----+------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "|_rpEhHWZmwnUWe96e...|           Bob Evans|  2.0|          38|      1|        0|   0|        0|                   1|         0|    0|           0|      0|               1|      0|    1|         0|      0|      0|            0|     0|  1|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0|\n",
      "|2R_hRr--5V1krRMfm...|     En Super Buffet|  2.0|           5|      0|        0|   0|        0|                   0|         0|    0|           0|      0|               0|      0|    0|         0|      1|      0|            0|     0|  0|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0|\n",
      "|H82T5LaYRnL9BispF...|      Domino's Pizza|  2.0|          12|      1|        0|   0|        0|                   0|         1|    1|           0|      0|               0|      0|    0|         0|      0|      0|            1|     0|  1|     0|    0|        0|     1|     0|    0|      0|       0|       0|       0|     0|      0|\n",
      "|JH4o5C4RyivBsExlK...|Chipotle Mexican ...|  2.0|          52|      1|        0|   0|        1|                   0|         0|    0|           0|      0|               0|      1|    0|         0|      0|      0|            0|     0|  0|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0|\n",
      "|oPSIb8Sdo7rsOOlj4...|             Wendy's|  2.0|          16|      1|        0|   0|        1|                   0|         0|    0|           0|      1|               0|      0|    0|         0|      0|      0|            0|     0|  0|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0|\n",
      "+--------------------+--------------------+-----+------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_b.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd93c6",
   "metadata": {},
   "source": [
    "### Deal with stars and reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ece01f",
   "metadata": {},
   "source": [
    "Stars and reviews could cause problems in the models. High review with high stars is good, but is bad with low stars.    \n",
    "Here we minus each restuarant's star by the average star of all restuarants, and time the normalized star by the square root of review count as the star_review_score.\n",
    "We hope this score could reflect how customers feel about the restuarant better than just using stars and review counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a473e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is overkill. This function could take a list of column and normalize them all.\n",
    "def normalize(df, columns):\n",
    "    aggExpr = []\n",
    "    for column in columns:\n",
    "        aggExpr.append(mean(df[column]).alias(column))\n",
    "    averages = df.agg(*aggExpr).collect()[0]\n",
    "    selectExpr = ['*']\n",
    "    for column in columns:\n",
    "        selectExpr.append((df[column] - averages[column]).alias('normalized_' + column))\n",
    "    return df.select(selectExpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "971bac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1113.5 KiB\n",
      "22/03/16 02:30:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1284.9 KiB\n",
      "22/03/16 02:30:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1441.0 KiB\n"
     ]
    }
   ],
   "source": [
    "normalize_star = normalize(df_b, ['stars'])\n",
    "normalize_star1 = normalize_star.withColumn('popularity_score', normalize_star['normalized_stars'] * sqrt(normalize_star['review_count']))\n",
    "normalize_star1 = normalize_star1.drop('stars', 'review_count', 'normalized_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f396f3ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1585.4 KiB\n",
      "22/03/16 02:30:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1715.5 KiB\n",
      "22/03/16 02:30:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1821.3 KiB\n",
      "22/03/16 02:30:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1913.5 KiB\n",
      "22/03/16 02:30:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1991.8 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+-------------------+\n",
      "|         business_id|           name|is_open|Nightlife|Bars|Fast_Food|American_Traditional|Sandwiches|Pizza|American_New|Burgers|Breakfast_Brunch|Mexican|Salad|Coffee_Tea|Chinese|Italian|Chicken_Wings|garage|lot|street|valet|validated|casual|classy|divey|hipster|intimate|romantic|touristy|trendy|upscale|   popularity_score|\n",
      "+--------------------+---------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+-------------------+\n",
      "|_rpEhHWZmwnUWe96e...|      Bob Evans|      1|        0|   0|        0|                   1|         0|    0|           0|      0|               1|      0|    1|         0|      0|      0|            0|     0|  1|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0| -8.770593603721569|\n",
      "|2R_hRr--5V1krRMfm...|En Super Buffet|      0|        0|   0|        0|                   0|         0|    0|           0|      0|               0|      0|    0|         0|      1|      0|            0|     0|  0|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0|-3.1814286794333886|\n",
      "|H82T5LaYRnL9BispF...| Domino's Pizza|      1|        0|   0|        0|                   0|         1|    1|           0|      0|               0|      0|    0|         0|      0|      0|            1|     0|  1|     0|    0|        0|     1|     0|    0|      0|       0|       0|       0|     0|      0| -4.928648117036867|\n",
      "+--------------------+---------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalize_star1.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95bc780",
   "metadata": {},
   "source": [
    "### Add topic Info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b7f57",
   "metadata": {},
   "source": [
    "Topic info was generated using NLP topic selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9ad6ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|         business_id|topicID|\n",
      "+--------------------+-------+\n",
      "|-AIj0yS_K7tnCKOtK...|      0|\n",
      "|0GAVuSOBf2LD8G7ce...|      0|\n",
      "|1vtDo34yXIToPOQty...|      0|\n",
      "+--------------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    }
   ],
   "source": [
    "table = 'red-formula-339716:gfds.b_id_with_topic'\n",
    "df_topic = spark.read.format('bigquery').option('table', table).load()\n",
    "df_topic.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "966506c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:52 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1984.3 KiB\n"
     ]
    }
   ],
   "source": [
    "topics = df_topic.select(\"topicID\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "topic_expr = [F.when(F.col(\"topicID\") == ty, 1).otherwise(0).alias(\"is_topic_\" + str(ty)) for ty in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9cd486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = df_topic.select(\"business_id\", *topic_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61ee3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_star1.join(df_topic, on = 'business_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f90b4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'name',\n",
       " 'is_open',\n",
       " 'Nightlife',\n",
       " 'Bars',\n",
       " 'Fast_Food',\n",
       " 'American_Traditional',\n",
       " 'Sandwiches',\n",
       " 'Pizza',\n",
       " 'American_New',\n",
       " 'Burgers',\n",
       " 'Breakfast_Brunch',\n",
       " 'Mexican',\n",
       " 'Salad',\n",
       " 'Coffee_Tea',\n",
       " 'Chinese',\n",
       " 'Italian',\n",
       " 'Chicken_Wings',\n",
       " 'garage',\n",
       " 'lot',\n",
       " 'street',\n",
       " 'valet',\n",
       " 'validated',\n",
       " 'casual',\n",
       " 'classy',\n",
       " 'divey',\n",
       " 'hipster',\n",
       " 'intimate',\n",
       " 'romantic',\n",
       " 'touristy',\n",
       " 'trendy',\n",
       " 'upscale',\n",
       " 'popularity_score',\n",
       " 'is_topic_0',\n",
       " 'is_topic_6',\n",
       " 'is_topic_5',\n",
       " 'is_topic_1',\n",
       " 'is_topic_3',\n",
       " 'is_topic_2',\n",
       " 'is_topic_4']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "45e8385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1113.5 KiB\n",
      "22/03/16 02:30:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1284.9 KiB\n",
      "22/03/16 02:30:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1441.0 KiB\n",
      "22/03/16 02:30:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1585.4 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+-------------------+----------+----------+----------+----------+----------+----------+----------+\n",
      "|         business_id|           name|is_open|Nightlife|Bars|Fast_Food|American_Traditional|Sandwiches|Pizza|American_New|Burgers|Breakfast_Brunch|Mexican|Salad|Coffee_Tea|Chinese|Italian|Chicken_Wings|garage|lot|street|valet|validated|casual|classy|divey|hipster|intimate|romantic|touristy|trendy|upscale|   popularity_score|is_topic_0|is_topic_6|is_topic_5|is_topic_1|is_topic_3|is_topic_2|is_topic_4|\n",
      "+--------------------+---------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+-------------------+----------+----------+----------+----------+----------+----------+----------+\n",
      "|_rpEhHWZmwnUWe96e...|      Bob Evans|      1|        0|   0|        0|                   1|         0|    0|           0|      0|               1|      0|    1|         0|      0|      0|            0|     0|  1|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0| -8.770593603721569|         0|         0|         0|         0|         1|         0|         0|\n",
      "|2R_hRr--5V1krRMfm...|En Super Buffet|      0|        0|   0|        0|                   0|         0|    0|           0|      0|               0|      0|    0|         0|      1|      0|            0|     0|  0|     0|    0|        0|     0|     0|    0|      0|       0|       0|       0|     0|      0|-3.1814286794333886|         0|         0|         0|         0|         1|         0|         0|\n",
      "|H82T5LaYRnL9BispF...| Domino's Pizza|      1|        0|   0|        0|                   0|         1|    1|           0|      0|               0|      0|    0|         0|      0|      0|            1|     0|  1|     0|    0|        0|     1|     0|    0|      0|       0|       0|       0|     0|      0| -4.928648117036867|         0|         0|         0|         0|         0|         0|         1|\n",
      "+--------------------+---------------+-------+---------+----+---------+--------------------+----------+-----+------------+-------+----------------+-------+-----+----------+-------+-------+-------------+------+---+------+-----+---------+------+------+-----+-------+--------+--------+--------+------+-------+-------------------+----------+----------+----------+----------+----------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1715.5 KiB\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61abb4",
   "metadata": {},
   "source": [
    "### Check point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc717d90",
   "metadata": {},
   "source": [
    "Saving the data back to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ac5b41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:30:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1821.3 KiB\n",
      "22/03/16 02:30:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1913.5 KiB\n",
      "22/03/16 02:30:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1991.8 KiB\n",
      "22/03/16 02:30:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:30:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:30:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1984.3 KiB\n",
      "22/03/16 02:30:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1850.8 KiB\n",
      "22/03/16 02:31:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1291.4 KiB\n",
      "22/03/16 02:31:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1086.7 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "table = 'red-formula-339716:gfds.business_cleanedishV1'\n",
    "df.write.format('bigquery') \\\n",
    "  .mode(\"overwrite\")        \\\n",
    "  .option('table', table)   \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3edae2",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12f024",
   "metadata": {},
   "source": [
    "### Check point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c3f63",
   "metadata": {},
   "source": [
    "Read the data from BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "768a4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'red-formula-339716:gfds.business_cleanedishV1'\n",
    "df = spark.read.format('bigquery').option('table', table).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28984c",
   "metadata": {},
   "source": [
    "### VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b024459",
   "metadata": {},
   "source": [
    "Spark ML seems to only take one column as inpuut, so we use VectorAssembler to combine all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a0c08409",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['is_open', 'American_New', 'American_Traditional', 'Bars',        \\\n",
    " 'Breakfast_Brunch', 'Burgers', 'Chicken_Wings', 'Chinese', 'Coffee_Tea',   \\\n",
    " 'Fast_Food', 'Italian', 'Mexican', 'Nightlife', 'Pizza', 'Salad',          \\\n",
    " 'Sandwiches', 'garage', 'lot', 'street', 'valet', 'validated', 'casual',   \\\n",
    " 'classy', 'divey', 'hipster', 'intimate', 'romantic', 'touristy','trendy', \\\n",
    " 'upscale', 'popularity_score', 'is_topic_0', 'is_topic_1', 'is_topic_2',  \\\n",
    " 'is_topic_3', 'is_topic_4', 'is_topic_5', 'is_topic_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "efe2276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+\n",
      "|         business_id|name|            features|\n",
      "+--------------------+----+--------------------+\n",
      "|u8xKhVGwBSlcBbH-e...| KFC|(38,[0,6,9,30,34]...|\n",
      "|8KuQwWcHwYmqV7FyT...| KFC|(38,[0,6,9,30,34]...|\n",
      "|-0mDPayQbOuJBw72Q...| KFC|(38,[0,6,9,30,34]...|\n",
      "+--------------------+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols = inputs, outputCol=\"features\")\n",
    "spDF = assembler.transform(df).drop(*inputs)\n",
    "\n",
    "spDF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a703213",
   "metadata": {},
   "source": [
    "Top users: C1kTSvNdJH_S2bBhitr6ZA, R1FVpAyl_BtxHBWdau2VLg, JzP5uJjhZb0Vj8J_bn3mOg, tgeFUChlh7v8bZFVl2-hjQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d13dff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for top user\n",
    "df_r_user1 = df_r.filter(df_r.user_id == 'C1kTSvNdJH_S2bBhitr6ZA')\n",
    "df_r_user1 = df_r_user1.select('business_id', 'stars', 'user_id').join(spDF, on = 'business_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "598b4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = df_r_user1.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b4b333de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98464c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|         business_id|stars|             user_id|                name|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|-XsgHkrblivxrbJpt...|  4.0|C1kTSvNdJH_S2bBhi...|     Firdous Express|(38,[0,21,30,32],...|\n",
      "|0jFrTHMEyIlHX0i_1...|  5.0|C1kTSvNdJH_S2bBhi...|       Belle's Bread|(38,[0,17,21,22,3...|\n",
      "|1c6PESqBJ2EQrjIVZ...|  5.0|C1kTSvNdJH_S2bBhi...|Wholly Joe's Chic...|(38,[9,13,17,21,3...|\n",
      "|3Qozg5zj-PelhTcdg...|  4.0|C1kTSvNdJH_S2bBhi...|      Salvi's Bistro|(38,[10,17,21,30,...|\n",
      "|5ulpV50MTkudwv-4a...|  4.0|C1kTSvNdJH_S2bBhi...|        Waffle House|(38,[0,2,4,17,21,...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f913c",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49a394f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 02:19:29 WARN org.apache.spark.ml.util.Instrumentation: [e9c6fbfb] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/03/12 02:19:32 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/03/12 02:19:32 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "22/03/12 02:19:32 WARN com.github.fommil.netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/03/12 02:19:32 WARN com.github.fommil.netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "22/03/12 02:19:32 WARN org.apache.spark.ml.util.Instrumentation: [e9c6fbfb] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol='stars')\n",
    "lrm = lr.fit(training)\n",
    "predictions_lrm = lrm.transform(test)\n",
    "train_pred_lrm = lrm.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c679421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.937383\n",
      "Root Mean Squared Error (RMSE) on train data = 0.933318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 57:===================================>                     (8 + 5) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.946286\n",
      "R2 on train data = 0.947039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 60:===================================================>    (12 + 1) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse_test = evaluator.evaluate(predictions_lrm)\n",
    "rmse_train = evaluator.evaluate(train_pred_lrm)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse_train)\n",
    "\n",
    "#R2\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"r2\", throughOrigin = True)\n",
    "\n",
    "r2_test = evaluator.evaluate(predictions_lrm)\n",
    "r2_train = evaluator.evaluate(train_pred_lrm)\n",
    "print(\"R2 on test data = %g\" % r2_test)\n",
    "print(\"R2 on train data = %g\" % r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e8ecd",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68a02fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol = 'features', labelCol='stars')\n",
    "dtm = dt.fit(training)\n",
    "predictions_dtm = dtm.transform(test)\n",
    "train_pred_dtm = dtm.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f060a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.974007\n",
      "Root Mean Squared Error (RMSE) on train data = 0.877509\n",
      "R2 on test data = 0.942007\n",
      "R2 on train data = 0.953183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 87:===================================================>    (12 + 1) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse_test = evaluator.evaluate(predictions_dtm)\n",
    "rmse_train = evaluator.evaluate(train_pred_dtm)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse_train)\n",
    "\n",
    "#F2\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"r2\", throughOrigin = True)\n",
    "\n",
    "r2_test = evaluator.evaluate(predictions_dtm)\n",
    "r2_train = evaluator.evaluate(train_pred_dtm)\n",
    "print(\"R2 on test data = %g\" % r2_test)\n",
    "print(\"R2 on train data = %g\" % r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c104367",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa6c7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(featuresCol = 'features', labelCol='stars')\n",
    "rfm = rf.fit(training)\n",
    "predictions_rfm = rfm.transform(test)\n",
    "train_pred_rfm = rfm.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cc1335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.893568\n",
      "Root Mean Squared Error (RMSE) on train data = 0.85789\n",
      "R2 on test data = 0.95119\n",
      "R2 on train data = 0.955253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 114:==================================================>    (12 + 1) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse_test = evaluator.evaluate(predictions_rfm)\n",
    "rmse_train = evaluator.evaluate(train_pred_rfm)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse_train)\n",
    "\n",
    "#F2\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"r2\", throughOrigin = True)\n",
    "\n",
    "r2_test = evaluator.evaluate(predictions_rfm)\n",
    "r2_train = evaluator.evaluate(train_pred_rfm)\n",
    "print(\"R2 on test data = %g\" % r2_test)\n",
    "print(\"R2 on train data = %g\" % r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b2a99",
   "metadata": {},
   "source": [
    "### GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ca6ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gbt = GBTRegressor(featuresCol = 'features', labelCol='stars', maxDepth=8, maxBins=16, maxIter=40, stepSize=0.05)\n",
    "gbtm = gbt.fit(training)\n",
    "predictions_gbtm = gbtm.transform(test)\n",
    "train_pred_gbtm = gbtm.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6de8c1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.17312\n",
      "Root Mean Squared Error (RMSE) on train data = 0.50573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2661:=============================================>        (11 + 2) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.912384\n",
      "R2 on train data = 0.984607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#RSME\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse_test = evaluator.evaluate(predictions_gbtm)\n",
    "rmse_train = evaluator.evaluate(train_pred_gbtm)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse_train)\n",
    "\n",
    "#F2\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"r2\", throughOrigin = True)\n",
    "\n",
    "r2_test = evaluator.evaluate(predictions_gbtm)\n",
    "r2_train = evaluator.evaluate(train_pred_gbtm)\n",
    "print(\"R2 on test data = %g\" % r2_test)\n",
    "print(\"R2 on train data = %g\" % r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20460a37",
   "metadata": {},
   "source": [
    "## Select Random Forest to Run Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b5c07",
   "metadata": {},
   "source": [
    "#### Using CrossValidator to finetune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce4660cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(labelCol=\"stars\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62d2eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [int(x) for x in np.linspace(start = 10, stop = 50, num = 5)]) \\\n",
    "    .addGrid(rf.maxDepth, [int(x) for x in np.linspace(start = 5, stop = 25, num = 5)]) \\\n",
    "    .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f829abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7075aa4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:33:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1087.8 KiB\n",
      "22/03/16 02:33:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1173.3 KiB\n",
      "22/03/16 02:33:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1243.3 KiB\n",
      "22/03/16 02:33:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1087.8 KiB\n",
      "22/03/16 02:33:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1173.3 KiB\n",
      "22/03/16 02:33:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1243.3 KiB\n",
      "22/03/16 02:33:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1302.6 KiB\n",
      "22/03/16 02:33:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1347.9 KiB\n",
      "22/03/16 02:33:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1382.6 KiB\n",
      "22/03/16 02:33:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1319.0 KiB\n",
      "22/03/16 02:33:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1251.6 KiB\n",
      "22/03/16 02:33:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1087.8 KiB\n",
      "22/03/16 02:33:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1173.3 KiB\n",
      "22/03/16 02:33:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1243.3 KiB\n",
      "22/03/16 02:33:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1302.6 KiB\n",
      "22/03/16 02:33:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1347.9 KiB\n",
      "22/03/16 02:33:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1382.6 KiB\n",
      "22/03/16 02:33:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1319.0 KiB\n",
      "22/03/16 02:33:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1251.6 KiB\n",
      "22/03/16 02:33:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1070.0 KiB\n",
      "22/03/16 02:33:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1209.7 KiB\n",
      "22/03/16 02:33:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1333.6 KiB\n",
      "22/03/16 02:33:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1446.3 KiB\n",
      "22/03/16 02:33:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1542.7 KiB\n",
      "22/03/16 02:33:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1070.0 KiB\n",
      "22/03/16 02:33:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1209.7 KiB\n",
      "22/03/16 02:33:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1333.6 KiB\n",
      "22/03/16 02:33:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1446.3 KiB\n",
      "22/03/16 02:33:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1542.7 KiB\n",
      "22/03/16 02:33:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1624.9 KiB\n",
      "22/03/16 02:33:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1690.5 KiB\n",
      "22/03/16 02:33:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1745.6 KiB\n",
      "22/03/16 02:33:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1752.9 KiB\n",
      "22/03/16 02:33:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1488.3 KiB\n",
      "22/03/16 02:33:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1070.0 KiB\n",
      "22/03/16 02:33:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1209.7 KiB\n",
      "22/03/16 02:33:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1333.6 KiB\n",
      "22/03/16 02:33:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1446.3 KiB\n",
      "22/03/16 02:33:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1542.7 KiB\n",
      "22/03/16 02:33:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1624.9 KiB\n",
      "22/03/16 02:33:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1690.5 KiB\n",
      "22/03/16 02:34:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1745.6 KiB\n",
      "22/03/16 02:34:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1752.9 KiB\n",
      "22/03/16 02:34:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1488.3 KiB\n",
      "22/03/16 02:34:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1292.7 KiB\n",
      "22/03/16 02:34:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1220.5 KiB\n",
      "22/03/16 02:34:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1149.7 KiB\n",
      "22/03/16 02:34:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1149.7 KiB\n",
      "22/03/16 02:34:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1331.7 KiB\n",
      "22/03/16 02:34:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1504.9 KiB\n",
      "22/03/16 02:34:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1658.7 KiB\n",
      "22/03/16 02:34:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1795.4 KiB\n",
      "22/03/16 02:34:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1916.2 KiB\n",
      "22/03/16 02:34:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1149.7 KiB\n",
      "22/03/16 02:34:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1331.7 KiB\n",
      "22/03/16 02:34:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1504.9 KiB\n",
      "22/03/16 02:34:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1658.7 KiB\n",
      "22/03/16 02:34:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1795.4 KiB\n",
      "22/03/16 02:34:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1916.2 KiB\n",
      "22/03/16 02:34:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2017.7 KiB\n",
      "22/03/16 02:34:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:34:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1996.5 KiB\n",
      "22/03/16 02:34:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2005.3 KiB\n",
      "22/03/16 02:34:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1906.1 KiB\n",
      "22/03/16 02:34:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1149.7 KiB\n",
      "22/03/16 02:34:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1331.7 KiB\n",
      "22/03/16 02:34:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1504.9 KiB\n",
      "22/03/16 02:34:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1658.7 KiB\n",
      "22/03/16 02:34:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1795.4 KiB\n",
      "22/03/16 02:34:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1916.2 KiB\n",
      "22/03/16 02:34:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2017.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:34:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:34:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1996.5 KiB\n",
      "22/03/16 02:34:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2005.3 KiB\n",
      "22/03/16 02:34:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1906.1 KiB\n",
      "22/03/16 02:34:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1715.3 KiB\n",
      "22/03/16 02:34:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1525.1 KiB\n",
      "22/03/16 02:34:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1181.2 KiB\n",
      "22/03/16 02:35:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1033.9 KiB\n",
      "22/03/16 02:35:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1130.6 KiB\n",
      "22/03/16 02:35:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1210.8 KiB\n",
      "22/03/16 02:35:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1272.7 KiB\n",
      "22/03/16 02:35:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1033.9 KiB\n",
      "22/03/16 02:35:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1130.6 KiB\n",
      "22/03/16 02:35:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1210.8 KiB\n",
      "22/03/16 02:35:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1272.7 KiB\n",
      "22/03/16 02:35:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1321.2 KiB\n",
      "22/03/16 02:35:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1360.0 KiB\n",
      "22/03/16 02:35:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1347.6 KiB\n",
      "22/03/16 02:35:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1289.4 KiB\n",
      "22/03/16 02:35:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1033.9 KiB\n",
      "22/03/16 02:35:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1130.6 KiB\n",
      "22/03/16 02:35:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1210.8 KiB\n",
      "22/03/16 02:35:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1272.7 KiB\n",
      "22/03/16 02:35:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1321.2 KiB\n",
      "22/03/16 02:35:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1360.0 KiB\n",
      "22/03/16 02:35:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1347.6 KiB\n",
      "22/03/16 02:35:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1289.4 KiB\n",
      "22/03/16 02:35:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1004.3 KiB\n",
      "22/03/16 02:35:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1004.3 KiB\n",
      "22/03/16 02:35:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1167.8 KiB\n",
      "22/03/16 02:35:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1320.5 KiB\n",
      "22/03/16 02:35:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1452.3 KiB\n",
      "22/03/16 02:35:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1564.6 KiB\n",
      "22/03/16 02:35:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1659.8 KiB\n",
      "22/03/16 02:35:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1004.3 KiB\n",
      "22/03/16 02:35:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1167.8 KiB\n",
      "22/03/16 02:35:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1320.5 KiB\n",
      "22/03/16 02:35:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1452.3 KiB\n",
      "22/03/16 02:35:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1564.6 KiB\n",
      "22/03/16 02:35:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1659.8 KiB\n",
      "22/03/16 02:35:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1735.2 KiB\n",
      "22/03/16 02:35:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1787.7 KiB\n",
      "22/03/16 02:35:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1554.5 KiB\n",
      "22/03/16 02:35:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1359.4 KiB\n",
      "22/03/16 02:35:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1161.6 KiB\n",
      "22/03/16 02:35:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1004.3 KiB\n",
      "22/03/16 02:35:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1167.8 KiB\n",
      "22/03/16 02:35:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1320.5 KiB\n",
      "22/03/16 02:35:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1452.3 KiB\n",
      "22/03/16 02:35:34 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1564.6 KiB\n",
      "22/03/16 02:35:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1659.8 KiB\n",
      "22/03/16 02:35:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1735.2 KiB\n",
      "22/03/16 02:35:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1787.7 KiB\n",
      "22/03/16 02:35:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1554.5 KiB\n",
      "22/03/16 02:35:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1359.4 KiB\n",
      "22/03/16 02:35:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1161.6 KiB\n",
      "22/03/16 02:35:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1052.2 KiB\n",
      "22/03/16 02:35:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1266.7 KiB\n",
      "22/03/16 02:35:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1052.2 KiB\n",
      "22/03/16 02:35:44 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1266.7 KiB\n",
      "22/03/16 02:35:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1473.7 KiB\n",
      "22/03/16 02:35:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1656.9 KiB\n",
      "22/03/16 02:35:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1813.8 KiB\n",
      "22/03/16 02:35:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1949.2 KiB\n",
      "22/03/16 02:35:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:35:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1052.2 KiB\n",
      "22/03/16 02:35:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1266.7 KiB\n",
      "22/03/16 02:35:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1473.7 KiB\n",
      "22/03/16 02:35:50 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1656.9 KiB\n",
      "22/03/16 02:35:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1813.8 KiB\n",
      "22/03/16 02:35:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1949.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:35:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:35:52 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:35:52 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:35:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:35:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1900.5 KiB\n",
      "22/03/16 02:35:53 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1525.8 KiB\n",
      "22/03/16 02:35:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1052.2 KiB\n",
      "22/03/16 02:35:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1266.7 KiB\n",
      "22/03/16 02:35:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1473.7 KiB\n",
      "22/03/16 02:35:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1656.9 KiB\n",
      "22/03/16 02:35:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1813.8 KiB\n",
      "22/03/16 02:35:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1949.2 KiB\n",
      "22/03/16 02:35:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:35:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:35:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:36:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "22/03/16 02:36:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1900.5 KiB\n",
      "22/03/16 02:36:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1525.8 KiB\n",
      "22/03/16 02:36:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1179.3 KiB\n",
      "22/03/16 02:36:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1039.4 KiB\n",
      "22/03/16 02:36:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1149.3 KiB\n",
      "22/03/16 02:36:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1241.8 KiB\n",
      "22/03/16 02:36:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1317.5 KiB\n",
      "22/03/16 02:36:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1039.4 KiB\n",
      "22/03/16 02:36:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1149.3 KiB\n",
      "22/03/16 02:36:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1241.8 KiB\n",
      "22/03/16 02:36:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1317.5 KiB\n",
      "22/03/16 02:36:41 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1383.2 KiB\n",
      "22/03/16 02:36:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1428.9 KiB\n",
      "22/03/16 02:36:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1462.7 KiB\n",
      "22/03/16 02:36:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1400.0 KiB\n",
      "22/03/16 02:36:42 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1219.5 KiB\n",
      "22/03/16 02:36:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1039.4 KiB\n",
      "22/03/16 02:36:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1149.3 KiB\n",
      "22/03/16 02:36:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1241.8 KiB\n",
      "22/03/16 02:36:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1317.5 KiB\n",
      "22/03/16 02:36:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1383.2 KiB\n",
      "22/03/16 02:36:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1428.9 KiB\n",
      "22/03/16 02:36:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1462.7 KiB\n",
      "22/03/16 02:36:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1400.0 KiB\n",
      "22/03/16 02:36:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1219.5 KiB\n",
      "22/03/16 02:36:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1156.9 KiB\n",
      "22/03/16 02:36:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1316.7 KiB\n",
      "22/03/16 02:36:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1458.1 KiB\n",
      "22/03/16 02:36:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1581.7 KiB\n",
      "22/03/16 02:36:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1685.3 KiB\n",
      "22/03/16 02:36:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1156.9 KiB\n",
      "22/03/16 02:36:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1316.7 KiB\n",
      "22/03/16 02:36:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1458.1 KiB\n",
      "22/03/16 02:36:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1581.7 KiB\n",
      "22/03/16 02:36:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1685.3 KiB\n",
      "22/03/16 02:36:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1765.4 KiB\n",
      "22/03/16 02:37:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1830.9 KiB\n",
      "22/03/16 02:37:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1881.5 KiB\n",
      "22/03/16 02:37:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1777.7 KiB\n",
      "22/03/16 02:37:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1625.9 KiB\n",
      "22/03/16 02:37:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1156.9 KiB\n",
      "22/03/16 02:37:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1316.7 KiB\n",
      "22/03/16 02:37:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1458.1 KiB\n",
      "22/03/16 02:37:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1581.7 KiB\n",
      "22/03/16 02:37:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1685.3 KiB\n",
      "22/03/16 02:37:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1765.4 KiB\n",
      "22/03/16 02:37:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1830.9 KiB\n",
      "22/03/16 02:37:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1881.5 KiB\n",
      "22/03/16 02:37:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1777.7 KiB\n",
      "22/03/16 02:37:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1625.9 KiB\n",
      "22/03/16 02:37:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1308.0 KiB\n",
      "22/03/16 02:37:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1002.1 KiB\n",
      "22/03/16 02:37:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1223.5 KiB\n",
      "22/03/16 02:37:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1002.1 KiB\n",
      "22/03/16 02:37:13 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1223.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/16 02:37:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1441.1 KiB\n",
      "22/03/16 02:37:14 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1641.1 KiB\n",
      "22/03/16 02:37:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1820.1 KiB\n",
      "22/03/16 02:37:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1975.6 KiB\n",
      "22/03/16 02:37:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:37:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1002.1 KiB\n",
      "22/03/16 02:37:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1223.5 KiB\n",
      "22/03/16 02:37:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1441.1 KiB\n",
      "22/03/16 02:37:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1641.1 KiB\n",
      "22/03/16 02:37:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1820.1 KiB\n",
      "22/03/16 02:37:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1975.6 KiB\n",
      "22/03/16 02:37:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:37:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/03/16 02:37:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/03/16 02:37:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/03/16 02:37:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:37:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1858.7 KiB\n",
      "22/03/16 02:37:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1002.1 KiB\n",
      "22/03/16 02:37:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1223.5 KiB\n",
      "22/03/16 02:37:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1441.1 KiB\n",
      "22/03/16 02:37:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1641.1 KiB\n",
      "22/03/16 02:37:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1820.1 KiB\n",
      "22/03/16 02:37:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1975.6 KiB\n",
      "22/03/16 02:37:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:37:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/03/16 02:37:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "22/03/16 02:37:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "22/03/16 02:37:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "22/03/16 02:37:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1858.7 KiB\n",
      "22/03/16 02:37:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1312.9 KiB\n",
      "22/03/16 02:37:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1039.9 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cvModel = crossval.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832dd41",
   "metadata": {},
   "source": [
    "#### Predicting on test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2323dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bestModel = cvModel.transform(test)\n",
    "training_bestModel = cvModel.transform(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bba5b",
   "metadata": {},
   "source": [
    "Evaluator - RMSE: 0.87 on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2461ce88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.92972\n",
      "Root Mean Squared Error (RMSE) on train data = 0.6625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4619:=================================>                     (8 + 5) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.945058\n",
      "R2 on train data = 0.973518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4622:=================================>                     (8 + 5) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse_test = evaluator.evaluate(predictions_bestModel)\n",
    "rmse_train = evaluator.evaluate(training_bestModel)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse_test)\n",
    "print(\"Root Mean Squared Error (RMSE) on train data = %g\" % rmse_train)\n",
    "\n",
    "#F2\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"r2\", throughOrigin = True)\n",
    "\n",
    "r2_test = evaluator.evaluate(predictions_bestModel)\n",
    "r2_train = evaluator.evaluate(training_bestModel)\n",
    "print(\"R2 on test data = %g\" % r2_test)\n",
    "print(\"R2 on train data = %g\" % r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abb4ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+------------------+\n",
      "|         business_id|             user_id|                name|stars|        prediction|\n",
      "+--------------------+--------------------+--------------------+-----+------------------+\n",
      "|D6vNP2CBjP3Lg7Xid...|C1kTSvNdJH_S2bBhi...|Columbus Fish Market|  5.0|4.9700932224741745|\n",
      "|B_W4Nq3-iFWV2ato5...|C1kTSvNdJH_S2bBhi...|The Refectory Res...|  5.0|  4.95669191919192|\n",
      "|ewFMsE_X1PcS09yuO...|C1kTSvNdJH_S2bBhi...|J. Gilbert's Wood...|  5.0| 4.936651860157553|\n",
      "|oRqgWTs4YBjEWCoz0...|C1kTSvNdJH_S2bBhi...|Gallo's Kitchen +...|  5.0| 4.932596473635128|\n",
      "|yKyKvEqumEes4FOQY...|C1kTSvNdJH_S2bBhi...|  The Top Steakhouse|  5.0|4.8913504919596456|\n",
      "|WQSziTOUaS36KC1es...|C1kTSvNdJH_S2bBhi...|       J Alexander's|  5.0| 4.858799435035911|\n",
      "|4ergn03AcRW2kzgvZ...|C1kTSvNdJH_S2bBhi...|      The Old Mohawk|  4.0| 4.798652349828822|\n",
      "|D8Va5ZW8snfom8pIs...|C1kTSvNdJH_S2bBhi...|German Village Co...|  4.0|  4.78269976268636|\n",
      "|Bn3gS9n9FtGSyiOub...|C1kTSvNdJH_S2bBhi...|     The Angry Baker|  5.0| 4.756780202129039|\n",
      "|BcopbuAklQD-7r8YT...|C1kTSvNdJH_S2bBhi...|  Kaya Grill & Sushi|  5.0| 4.678860736856958|\n",
      "|o1swOI_fdPYIEKb0k...|C1kTSvNdJH_S2bBhi...|Cap City Fine Din...|  5.0| 4.676703016955574|\n",
      "|rhSwg3EFZqOyOlYwb...|C1kTSvNdJH_S2bBhi...|      Wurst Und Bier|  3.0| 4.674958816666936|\n",
      "|6xj8KDXNyZbowU99K...|C1kTSvNdJH_S2bBhi...|Marcella's Columb...|  5.0| 4.658834350709733|\n",
      "|5CSb10ZhZB1CJ6OgC...|C1kTSvNdJH_S2bBhi...|       Polaris Grill|  5.0|  4.60561635440016|\n",
      "|5CSb10ZhZB1CJ6OgC...|C1kTSvNdJH_S2bBhi...|       Polaris Grill|  4.0|  4.60561635440016|\n",
      "|KCl8BmcHa6Tgw48C0...|C1kTSvNdJH_S2bBhi...|            Club 185|  5.0|  4.60059051514463|\n",
      "|gmIyAldUFb9e8ekRY...|C1kTSvNdJH_S2bBhi...|       M at Miranova|  4.0| 4.599603174603175|\n",
      "|RsygVR-u828vAnjML...|C1kTSvNdJH_S2bBhi...|Gresso's Restaura...|  4.0| 4.572286180590295|\n",
      "|k6mmr7upHW85nsyRZ...|C1kTSvNdJH_S2bBhi...|Brazenhead Irish Pub|  3.0| 4.533435917952456|\n",
      "|1c6PESqBJ2EQrjIVZ...|C1kTSvNdJH_S2bBhi...|Wholly Joe's Chic...|  4.0| 4.528773926695889|\n",
      "|hKa__ZhGPo5NmTq1z...|C1kTSvNdJH_S2bBhi...|China Dynasty Chi...|  4.0| 4.506915210632129|\n",
      "|2AMrPSOA7VzjPZmqv...|C1kTSvNdJH_S2bBhi...|     Cataland Kuzina|  5.0| 4.482710325742139|\n",
      "|Zu9Jg3FzpxzP4ckWx...|C1kTSvNdJH_S2bBhi...|Windward Passage ...|  3.0| 4.459803334489746|\n",
      "|dHLwNv60qXlm1N4xg...|C1kTSvNdJH_S2bBhi...|Little Palace Bar...|  4.0| 4.457373351049822|\n",
      "|a4OoQLUwdc_PgPa3k...|C1kTSvNdJH_S2bBhi...|Katzinger's Delic...|  5.0| 4.451708202983747|\n",
      "|O6I69Elz0iYm2nHmJ...|C1kTSvNdJH_S2bBhi...|        Lucky Dragon|  5.0| 4.417808039589261|\n",
      "|yu4iVdak9eC_R1eG8...|C1kTSvNdJH_S2bBhi...|   Smith & Wollensky|  1.0| 4.417098287235974|\n",
      "|uZkMqmw2oH2CvL69c...|C1kTSvNdJH_S2bBhi...|Alex's Bistro on ...|  4.0| 4.407610205492394|\n",
      "|DjQ7OlArf4FnnAR4z...|C1kTSvNdJH_S2bBhi...|King Gyros Greek ...|  5.0| 4.406715724328662|\n",
      "|ff1kex_dJGG5Fn3YD...|C1kTSvNdJH_S2bBhi...|    Banana Bean Caf|  4.0|  4.38613664546189|\n",
      "+--------------------+--------------------+--------------------+-----+------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4639:=================================>                     (8 + 5) / 13]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions_bestModel.select('business_id', 'user_id', 'name', 'stars', 'prediction').distinct().orderBy(desc('prediction')).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "061d0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "180e3789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>popularity_score</td>\n",
       "      <td>22.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Italian</td>\n",
       "      <td>4.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lot</td>\n",
       "      <td>4.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>classy</td>\n",
       "      <td>4.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>is_topic_2</td>\n",
       "      <td>4.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_open</td>\n",
       "      <td>3.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>casual</td>\n",
       "      <td>3.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breakfast_Brunch</td>\n",
       "      <td>3.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American_New</td>\n",
       "      <td>3.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>is_topic_5</td>\n",
       "      <td>2.98%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Importance\n",
       "30  popularity_score     22.84%\n",
       "10           Italian      4.48%\n",
       "17               lot      4.27%\n",
       "22            classy      4.21%\n",
       "33        is_topic_2      4.18%\n",
       "0            is_open      3.97%\n",
       "21            casual      3.75%\n",
       "4   Breakfast_Brunch      3.52%\n",
       "1       American_New      3.16%\n",
       "36        is_topic_5      2.98%"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_Importance = pd.DataFrame(list(zip(assembler.getInputCols(), bestmodel.featureImportances)), columns = ['Feature', 'Importance'])\n",
    "pd_Importance = pd_Importance.sort_values('Importance', ascending = False, axis = 0)\n",
    "pd_Importance['Importance'] = pd_Importance['Importance'].map(\"{:.2%}\".format)\n",
    "pd_Importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1420c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_Importance['Importance'] = pd_Importance['Importance'].str.strip('%').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "22dddd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_Importance = pd_Importance.set_index(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "57d28bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>popularity_score</th>\n",
       "      <td>22.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italian</th>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lot</th>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classy</th>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_topic_2</th>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Importance\n",
       "Feature                     \n",
       "popularity_score       22.84\n",
       "Italian                 4.48\n",
       "lot                     4.27\n",
       "classy                  4.21\n",
       "is_topic_2              4.18"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_Importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4fc7fdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Feature'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_Importance[:10].plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5e6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96fa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}